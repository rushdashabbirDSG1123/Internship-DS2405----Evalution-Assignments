{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98bf0478",
   "metadata": {},
   "source": [
    "# Batch - DS2405\n",
    "\n",
    "Assignment 4 - Webscrapping Selenium Exception handling\n",
    "\n",
    "Name - Rushda Shabbir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab3af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import html5lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4439a7a",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f4985",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url\n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\n",
    "Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bd91e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Viewed Video on YouTube from Wikipedia\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"[7]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>14.82</td>\n",
       "      <td>November 2, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"[10]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.49</td>\n",
       "      <td>August 4, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[18]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.94</td>\n",
       "      <td>July 10, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Bath Song\"[19]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.79</td>\n",
       "      <td>November 24, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Wheels on the Bus\"[20]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.34</td>\n",
       "      <td>July 16, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.33</td>\n",
       "      <td>April 14, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Shape of You\"[26]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.30</td>\n",
       "      <td>October 25, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Phonics Song with Two Words\"[29]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.90</td>\n",
       "      <td>May 2, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Uptown Funk\"[30]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.28</td>\n",
       "      <td>July 17, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>5.22</td>\n",
       "      <td>March 15, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Learning Colors ‚Äì Colorful Eggs on a Farm\"[36]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>5.15</td>\n",
       "      <td>March 1, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.72</td>\n",
       "      <td>May 19, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.66</td>\n",
       "      <td>March 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Masha and the Bear ‚Äì Recipe for Disaster\"[39]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.59</td>\n",
       "      <td>February 18, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>4.14</td>\n",
       "      <td>January 21, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[41]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>4.11</td>\n",
       "      <td>January 9, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Sugar\"[42]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>4.08</td>\n",
       "      <td>October 31, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Counting Stars\"[43]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>4.05</td>\n",
       "      <td>October 29, 2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                       Video Name  \\\n",
       "0      1                            \"Baby Shark Dance\"[7]   \n",
       "1      2                                  \"Despacito\"[10]   \n",
       "2      3                       \"Johny Johny Yes Papa\"[18]   \n",
       "3      4                                  \"Bath Song\"[19]   \n",
       "4      5                          \"Wheels on the Bus\"[20]   \n",
       "5      6                              \"See You Again\"[21]   \n",
       "6      7                               \"Shape of You\"[26]   \n",
       "7      8                \"Phonics Song with Two Words\"[29]   \n",
       "8      9                                \"Uptown Funk\"[30]   \n",
       "9     10                              \"Gangnam Style\"[31]   \n",
       "10    11  \"Learning Colors ‚Äì Colorful Eggs on a Farm\"[36]   \n",
       "11    12                             \"Dame Tu Cosita\"[37]   \n",
       "12    13                                     \"Axel F\"[38]   \n",
       "13    14   \"Masha and the Bear ‚Äì Recipe for Disaster\"[39]   \n",
       "14    15                        \"Baa Baa Black Sheep\"[40]   \n",
       "15    16                             \"Lakdi Ki Kathi\"[41]   \n",
       "16    17                                      \"Sugar\"[42]   \n",
       "17    18                             \"Counting Stars\"[43]   \n",
       "\n",
       "                                             Uploader  Views  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories  14.82   \n",
       "1                                          Luis Fonsi   8.49   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs   6.94   \n",
       "3                          Cocomelon - Nursery Rhymes   6.79   \n",
       "4                          Cocomelon - Nursery Rhymes   6.34   \n",
       "5                                         Wiz Khalifa   6.33   \n",
       "6                                          Ed Sheeran   6.30   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs   5.90   \n",
       "8                                         Mark Ronson   5.28   \n",
       "9                                                 Psy   5.22   \n",
       "10                                        Miroshka TV   5.15   \n",
       "11                                      Ultra Records   4.72   \n",
       "12                                         Crazy Frog   4.66   \n",
       "13                                         Get Movies   4.59   \n",
       "14                         Cocomelon - Nursery Rhymes   4.14   \n",
       "15                                       Jingle Toons   4.11   \n",
       "16                                           Maroon 5   4.08   \n",
       "17                                        OneRepublic   4.05   \n",
       "\n",
       "          Upload Date  \n",
       "0    November 2, 2020  \n",
       "1      August 4, 2017  \n",
       "2       July 10, 2017  \n",
       "3   November 24, 2012  \n",
       "4       July 16, 2010  \n",
       "5      April 14, 2010  \n",
       "6    October 25, 2009  \n",
       "7         May 2, 2009  \n",
       "8       July 17, 2008  \n",
       "9      March 15, 2008  \n",
       "10      March 1, 2008  \n",
       "11       May 19, 2006  \n",
       "12     March 12, 2006  \n",
       "13  February 18, 2006  \n",
       "14   January 21, 2006  \n",
       "15    January 9, 2006  \n",
       "16   October 31, 2005  \n",
       "17   October 29, 2005  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the web page by Urls\n",
    "driver = webdriver.Chrome()\n",
    "url=\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "# Empty list for scraping data\n",
    "Rank =[]\n",
    "Name =[]\n",
    "Artist =[]\n",
    "Upload_date=[]\n",
    "Views=[]\n",
    "\n",
    "\n",
    "# scraping Name and Rank\n",
    "try:\n",
    "    nam=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "    for i in nam:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    Name.append('-')\n",
    "#print(len(Name))\n",
    "#print(Name)\n",
    "\n",
    "\n",
    "# scraping Artist name\n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    Artist.append('-')\n",
    "    \n",
    "#print(Artist)\n",
    "#print(len(Artist))\n",
    "\n",
    "\n",
    "# scraping Upload Date\n",
    "try:\n",
    "    upload_date=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]')\n",
    "    for i in upload_date:\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Upload_date.append('-')  \n",
    "except StaleElementReferenceException:\n",
    "    Upload_date.append('-')\n",
    "    \n",
    "#print(Upload_date)\n",
    "#print(len(Upload_date))\n",
    "\n",
    "\n",
    "# scraping Views\n",
    "try:\n",
    "    views=driver.find_elements(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "    for i in views:\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    Views.append('-')\n",
    "    \n",
    "#print(Views)\n",
    "#print(len(Views))\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "# Dataframe for scrap data\n",
    "print('Most Viewed Video on YouTube from Wikipedia')\n",
    "Wiki_youtube_df=pd.DataFrame({\n",
    "    'Video Name':Name[:18],\n",
    "    'Uploader':Artist[:18],\n",
    "    'Views':Views[:18],\n",
    "    'Upload Date':Upload_date[:18]})\n",
    "\n",
    "#set the Rank as index\n",
    "Wiki_youtube_df['Rank'] = Wiki_youtube_df.index\n",
    "Wiki_youtube_df['Rank'] = range(1, len(Wiki_youtube_df) + 1)\n",
    "\n",
    "#Wiki_youtube_df= pd.DataFrame(Wiki_youtube_df)\n",
    "\n",
    "# Set the 'Rank' column as the first column\n",
    "Wiki_youtube_df= Wiki_youtube_df[['Rank', 'Video Name', 'Uploader', 'Views', 'Upload Date']]\n",
    "Wiki_youtube_df\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16766ce7",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b9a2e8",
   "metadata": {},
   "source": [
    "2. Scrape the details team India‚Äôs international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e19a1930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series: 5\n",
      "Date: 5\n",
      "Time: 5\n",
      "Place: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asia Cup Women T20 2024</td>\n",
       "      <td>Rangiri Dambulla International Stadium,</td>\n",
       "      <td>26 Jul</td>\n",
       "      <td>14:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India Tour Of Sri Lanka T20 Series 2024</td>\n",
       "      <td>Pallekele International Cricket Stadium,</td>\n",
       "      <td>27 Jul</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India Tour Of Sri Lanka T20 Series 2024</td>\n",
       "      <td>Pallekele International Cricket Stadium,</td>\n",
       "      <td>28 Jul</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India Tour Of Sri Lanka T20 Series 2024</td>\n",
       "      <td>Pallekele International Cricket Stadium,</td>\n",
       "      <td>30 Jul</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India Tour Of Sri Lanka ODI Series 2024</td>\n",
       "      <td>R Premadasa International Stadium,</td>\n",
       "      <td>2 Aug</td>\n",
       "      <td>14:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Series  \\\n",
       "0                  Asia Cup Women T20 2024   \n",
       "1  India Tour Of Sri Lanka T20 Series 2024   \n",
       "2  India Tour Of Sri Lanka T20 Series 2024   \n",
       "3  India Tour Of Sri Lanka T20 Series 2024   \n",
       "4  India Tour Of Sri Lanka ODI Series 2024   \n",
       "\n",
       "                                     Place     Date       Time  \n",
       "0   Rangiri Dambulla International Stadium,  26 Jul  14:00 IST  \n",
       "1  Pallekele International Cricket Stadium,  27 Jul  19:00 IST  \n",
       "2  Pallekele International Cricket Stadium,  28 Jul  19:00 IST  \n",
       "3  Pallekele International Cricket Stadium,  30 Jul  19:00 IST  \n",
       "4        R Premadasa International Stadium,   2 Aug  14:30 IST  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#get webpage\n",
    "driver = webdriver.Chrome()\n",
    "url=\"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "# from bcci.tv home page reach out the international fixture page\n",
    "search= driver.find_element(By.XPATH, '//div[@class=\"imw-tabs international-tabs\"]/a[2]')      \n",
    "search.click()\n",
    "\n",
    "#create the list\n",
    "Series=[]\n",
    "Place =[]\n",
    "Date =[]\n",
    "Time=[]\n",
    "\n",
    "# Scraping series\n",
    "time.sleep(5)\n",
    "sris=driver.find_elements(By.XPATH, '//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in sris:\n",
    "    if i.text is None :\n",
    "        Series.append(\"--\") \n",
    "    else:\n",
    "        Series.append(i.text)\n",
    "        \n",
    "#Scrapping date\n",
    "time.sleep(5)\n",
    "dat=driver.find_elements(By.XPATH, '//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in dat:\n",
    "    if i.text is None :\n",
    "        Date.append(\"--\") \n",
    "    else:\n",
    "        Date.append(i.text)\n",
    "        \n",
    "#Scrapping time\n",
    "time.sleep(5)\n",
    "tim=driver.find_elements(By.XPATH, '//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in tim:\n",
    "    if i.text is None :\n",
    "        Time.append(\"--\") \n",
    "    else:\n",
    "        Time.append(i.text)\n",
    "        \n",
    "# Scrapping place\n",
    "time.sleep(5)\n",
    "plce=driver.find_elements(By.XPATH, '//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in plce:\n",
    "    if i.text is None :\n",
    "        Place.append(\"--\") \n",
    "    else:\n",
    "        Place.append(i.text)\n",
    "        \n",
    "#close web page\n",
    "driver.close()\n",
    "        \n",
    "# print len of all scraping Data\n",
    "print(\"Series:\",len(Series))\n",
    "print(\"Date:\",len(Date))\n",
    "print(\"Time:\",len(Time))\n",
    "print(\"Place:\",len(Place))\n",
    "\n",
    "\n",
    "#making Data Frame\n",
    "T20_df=pd.DataFrame({\n",
    "    \"Series\":Series,\n",
    "    \"Place \":Place ,\n",
    "    \"Date\":Date,\n",
    "    \"Time\":Time\n",
    "})\n",
    "T20_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49aa9a",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b071e",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36700f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all useable libraries 1st\n",
    "\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,ElementNotInteractableException\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "url=\"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Click On Ecomoy Option\n",
    "time.sleep(3)\n",
    "economy = driver.find_element(By.XPATH, '//*[@id=\"top\"]/div[2]/div[2]/button')     \n",
    "economy.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a172d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on India Option\n",
    "time.sleep(3)\n",
    "try:\n",
    "    india = driver.find_element(By.XPATH, '//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')\n",
    "    india.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"Exception raised\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51784c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on GDP on Indian States in Indian States\n",
    "time.sleep(3)\n",
    "gdp = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')      \n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ce461e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank : 68\n",
      "state : 68\n",
      "GSDP for 22 -23 : 33\n",
      "GSDP for 23 -24 : 33\n",
      "Share for 21 - 22 : 33\n",
      "GDP : 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Rank</th>\n",
       "      <th>State Names</th>\n",
       "      <th>GSDP_22_23</th>\n",
       "      <th>GSDP_23_24</th>\n",
       "      <th>Share_21_22</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>13.17%</td>\n",
       "      <td>414.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>8.78%</td>\n",
       "      <td>276.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,269,995</td>\n",
       "      <td>1,978,094</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>264.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>2,258,040</td>\n",
       "      <td>1,975,595</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>263.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>2,230,609</td>\n",
       "      <td>1,928,683</td>\n",
       "      <td>8.17%</td>\n",
       "      <td>257.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,531,758</td>\n",
       "      <td>1,329,238</td>\n",
       "      <td>5.63%</td>\n",
       "      <td>177.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,365,849</td>\n",
       "      <td>1,193,489</td>\n",
       "      <td>5.06%</td>\n",
       "      <td>159.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,303,524</td>\n",
       "      <td>1,148,471</td>\n",
       "      <td>4.87%</td>\n",
       "      <td>153.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,308,034</td>\n",
       "      <td>1,124,204</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>150.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,246,471</td>\n",
       "      <td>1,092,964</td>\n",
       "      <td>4.63%</td>\n",
       "      <td>145.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>1,046,188</td>\n",
       "      <td>934,542</td>\n",
       "      <td>3.96%</td>\n",
       "      <td>124.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>1,014,688</td>\n",
       "      <td>881,336</td>\n",
       "      <td>3.73%</td>\n",
       "      <td>117.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>984,055</td>\n",
       "      <td>868,905</td>\n",
       "      <td>3.68%</td>\n",
       "      <td>116.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>753,177</td>\n",
       "      <td>662,886</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>88.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>751,396</td>\n",
       "      <td>650,302</td>\n",
       "      <td>2.76%</td>\n",
       "      <td>86.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>676,164</td>\n",
       "      <td>617,192</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>493,167</td>\n",
       "      <td>411,454</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>464,399</td>\n",
       "      <td>410,525</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>393,722</td>\n",
       "      <td>358,863</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>47.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>303,781</td>\n",
       "      <td>267,143</td>\n",
       "      <td>1.13%</td>\n",
       "      <td>35.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>224,226</td>\n",
       "      <td>193,352</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>25.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>191,728</td>\n",
       "      <td>172,162</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>22.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>93,672</td>\n",
       "      <td>84,266</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>11.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>72,636</td>\n",
       "      <td>62,550</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>54,285</td>\n",
       "      <td>46,096</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>6.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>49,643</td>\n",
       "      <td>43,810</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>42,697</td>\n",
       "      <td>38,785</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>42,756</td>\n",
       "      <td>37,557</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>36,594</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>39,630</td>\n",
       "      <td>34,775</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>35,643</td>\n",
       "      <td>31,038</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>27,824</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>10,371</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State Rank                State Names GSDP_22_23 GSDP_23_24 Share_21_22  \\\n",
       "0           1                Maharashtra          -  3,108,022      13.17%   \n",
       "1           2                 Tamil Nadu  2,364,514  2,071,286       8.78%   \n",
       "2           3                  Karnataka  2,269,995  1,978,094       8.38%   \n",
       "3           4              Uttar Pradesh  2,258,040  1,975,595       8.37%   \n",
       "4           5                    Gujarat  2,230,609  1,928,683       8.17%   \n",
       "5           6                West Bengal  1,531,758  1,329,238       5.63%   \n",
       "6           7                  Rajasthan  1,365,849  1,193,489       5.06%   \n",
       "7           8             Andhra Pradesh  1,303,524  1,148,471       4.87%   \n",
       "8           9                  Telangana  1,308,034  1,124,204       4.76%   \n",
       "9          10             Madhya Pradesh  1,246,471  1,092,964       4.63%   \n",
       "10         11                     Kerala  1,046,188    934,542       3.96%   \n",
       "11         12                      Delhi  1,014,688    881,336       3.73%   \n",
       "12         13                    Haryana    984,055    868,905       3.68%   \n",
       "13         14                     Odisha    753,177    662,886       2.81%   \n",
       "14         15                      Bihar    751,396    650,302       2.76%   \n",
       "15         16                     Punjab    676,164    617,192       2.62%   \n",
       "16         17                      Assam    493,167    411,454       1.74%   \n",
       "17         18               Chhattisgarh    464,399    410,525       1.74%   \n",
       "18         19                  Jharkhand    393,722    358,863       1.52%   \n",
       "19         20                Uttarakhand    303,781    267,143       1.13%   \n",
       "20         21            Jammu & Kashmir    224,226    193,352       0.82%   \n",
       "21         22           Himachal Pradesh    191,728    172,162       0.73%   \n",
       "22         23                        Goa     93,672     84,266       0.36%   \n",
       "23         24                    Tripura     72,636     62,550       0.27%   \n",
       "24         25                 Chandigarh     54,285     46,096       0.20%   \n",
       "25         26                 Puducherry     49,643     43,810       0.19%   \n",
       "26         27                  Meghalaya     42,697     38,785       0.16%   \n",
       "27         28                     Sikkim     42,756     37,557       0.16%   \n",
       "28         29                    Manipur          -     36,594       0.16%   \n",
       "29         30          Arunachal Pradesh     39,630     34,775       0.15%   \n",
       "30         31                   Nagaland     35,643     31,038       0.13%   \n",
       "31         32                    Mizoram          -     27,824       0.12%   \n",
       "32         33  Andaman & Nicobar Islands          -     10,371       0.04%   \n",
       "\n",
       "        GDP  \n",
       "0   414.928  \n",
       "1   276.522  \n",
       "2   264.080  \n",
       "3   263.747  \n",
       "4   257.484  \n",
       "5   177.456  \n",
       "6   159.334  \n",
       "7   153.324  \n",
       "8   150.084  \n",
       "9   145.913  \n",
       "10  124.764  \n",
       "11  117.660  \n",
       "12  116.001  \n",
       "13   88.497  \n",
       "14   86.817  \n",
       "15   82.397  \n",
       "16   54.930  \n",
       "17   54.806  \n",
       "18   47.909  \n",
       "19   35.664  \n",
       "20   25.813  \n",
       "21   22.984  \n",
       "22   11.250  \n",
       "23    8.351  \n",
       "24    6.154  \n",
       "25    5.849  \n",
       "26    5.178  \n",
       "27    5.014  \n",
       "28    4.885  \n",
       "29    4.643  \n",
       "30    4.144  \n",
       "31    3.715  \n",
       "32    1.385  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create scrapping List\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_22_23=[]\n",
    "GSDP_23_24=[]\n",
    "Share_21_22=[]\n",
    "GDP=[]\n",
    "\n",
    "# scraping Rank \n",
    "time.sleep(5)\n",
    "try:\n",
    "    ranks=driver.find_elements(By.XPATH, \"//td[@class='data1']\")\n",
    "    for i in ranks:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"--\")\n",
    "\n",
    "\n",
    "\n",
    "# scraping State\n",
    "time.sleep(5)\n",
    "try:\n",
    "    states=driver.find_elements(By.XPATH, \"//td[@class='name']\")\n",
    "    for i in states:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "     State.append(\"--\")\n",
    "\n",
    "\n",
    "\n",
    "# scraping GSDP for 22-23 because here 18 _19 not showing\n",
    "time.sleep(5)\n",
    "try:\n",
    "    gdp_23=driver.find_elements(By.XPATH, '//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "    for i in gdp_23:\n",
    "        GSDP_22_23.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_22_23.append(\"--\") \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# scraping GSDP 23-24 because here not shown 19_ 20\n",
    "time.sleep(5)\n",
    "try:\n",
    "    gdp_24=driver.find_elements(By.XPATH, '//table[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "    for i in gdp_24:\n",
    "        GSDP_23_24.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_23_24.append(\"--\") \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scraping the Share for 21_22 here also not shown 18 _ 19\n",
    "time.sleep(5)\n",
    "try:\n",
    "    shres=driver.find_elements(By.XPATH, '//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "    for i in shres:\n",
    "        Share_21_22.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share_21_22.append(\"--\") \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scraping GDP\n",
    "time.sleep(5)\n",
    "try:\n",
    "    gdp=driver.find_elements(By.XPATH, '//table[@id=\"table_id\"]/tbody/tr/td[7]')\n",
    "    for i in gdp:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException:\n",
    "        GDP.append(\"--\") \n",
    "\n",
    "# Close web page\n",
    "driver.quit()\n",
    "\n",
    "# print of all scrapping data\n",
    "print(\"Rank :\",len(Rank))\n",
    "\n",
    "print(\"state :\",len(State))\n",
    "\n",
    "print(\"GSDP for 22 -23 :\",len(GSDP_22_23))\n",
    "\n",
    "print(\"GSDP for 23 -24 :\",len(GSDP_23_24))\n",
    "\n",
    "print(\"Share for 21 - 22 :\",len(Share_21_22))\n",
    "\n",
    "print(\"GDP :\",len(GDP))\n",
    "\n",
    "\n",
    "\n",
    "# making Data Frame\n",
    "state_GDP_df=pd.DataFrame({\n",
    "    \"State Rank\":Rank[:33],\n",
    "    \"State Names\":State[:33],\n",
    "    \"GSDP_22_23\":GSDP_22_23[:33],\n",
    "    \"GSDP_23_24\":GSDP_23_24[:33],\n",
    "    \"Share_21_22\":Share_21_22[:33],\n",
    "    \"GDP\":GDP[:33]\n",
    "})\n",
    "state_GDP_df\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26188161",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used \n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84c8b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException ,ElementNotInteractableException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Open web page\n",
    "driver = webdriver.Chrome()\n",
    "url=\"https://github.com/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "#create Lists\n",
    "R_title=[]\n",
    "R_discr=[]\n",
    "contributers=[]\n",
    "Language=[]\n",
    "\n",
    "# click on Open Source\n",
    "explore = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[4]/button')      \n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6abb43ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception Raised Message: element not interactable\n",
      "  (Session info: chrome=126.0.6478.183)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF79702EEB2+31554]\n",
      "\t(No symbol) [0x00007FF796FA7EE9]\n",
      "\t(No symbol) [0x00007FF796E68559]\n",
      "\t(No symbol) [0x00007FF796EB97C2]\n",
      "\t(No symbol) [0x00007FF796EAC151]\n",
      "\t(No symbol) [0x00007FF796EDD02A]\n",
      "\t(No symbol) [0x00007FF796EABA76]\n",
      "\t(No symbol) [0x00007FF796EDD240]\n",
      "\t(No symbol) [0x00007FF796EFC977]\n",
      "\t(No symbol) [0x00007FF796EDCDD3]\n",
      "\t(No symbol) [0x00007FF796EAA33B]\n",
      "\t(No symbol) [0x00007FF796EAAED1]\n",
      "\tGetHandleVerifier [0x00007FF797338B2D+3217341]\n",
      "\tGetHandleVerifier [0x00007FF797385AF3+3532675]\n",
      "\tGetHandleVerifier [0x00007FF79737B0F0+3489152]\n",
      "\tGetHandleVerifier [0x00007FF7970DE786+750614]\n",
      "\t(No symbol) [0x00007FF796FB376F]\n",
      "\t(No symbol) [0x00007FF796FAEB24]\n",
      "\t(No symbol) [0x00007FF796FAECB2]\n",
      "\t(No symbol) [0x00007FF796F9E17F]\n",
      "\tBaseThreadInitThunk [0x00007FFA597B7374+20]\n",
      "\tRtlUserThreadStart [0x00007FFA59FDCC91+33]\n",
      "\n",
      "Ripository Titles: 15\n",
      "Ripository Description: 15\n",
      "Contributors Count: 15\n",
      "Language Ussed: 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ripository Tiles</th>\n",
       "      <th>Ripository Description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stirling-Tools / Stirling-PDF</td>\n",
       "      <td>#1 Locally hosted web application that allows ...</td>\n",
       "      <td>2,537</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netflix / maestro</td>\n",
       "      <td>Maestro: Netflix‚Äôs Workflow Orchestrator</td>\n",
       "      <td>66</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public-apis / public-apis</td>\n",
       "      <td>A collective list of free APIs</td>\n",
       "      <td>32,809</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta-llama / codellama</td>\n",
       "      <td>Inference code for CodeLlama models</td>\n",
       "      <td>1,819</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mem0ai / mem0</td>\n",
       "      <td>The memory layer for Personalized AI</td>\n",
       "      <td>1,634</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>drawdb-io / drawdb</td>\n",
       "      <td>Free, simple, and intuitive online database de...</td>\n",
       "      <td>920</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DarkFlippers / unleashed-firmware</td>\n",
       "      <td>Flipper Zero Unleashed Firmware</td>\n",
       "      <td>1,355</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stretchr / testify</td>\n",
       "      <td>A toolkit with common assertions and mocks tha...</td>\n",
       "      <td>1,574</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meta-llama / llama3</td>\n",
       "      <td>The official Meta Llama 3 GitHub site</td>\n",
       "      <td>2,594</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hoppscotch / hoppscotch</td>\n",
       "      <td>Open source API development ecosystem - https:...</td>\n",
       "      <td>4,295</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gabime / spdlog</td>\n",
       "      <td>Fast C++ logging library.</td>\n",
       "      <td>4,395</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ggerganov / llama.cpp</td>\n",
       "      <td>LLM inference in C/C++</td>\n",
       "      <td>8,939</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lz4 / lz4</td>\n",
       "      <td>Extremely Fast Compression algorithm</td>\n",
       "      <td>1,354</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openstatusHQ / openstatus</td>\n",
       "      <td>üèì The open-source synthetic monitoring platform üèì</td>\n",
       "      <td>345</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>qdrant / qdrant</td>\n",
       "      <td>Qdrant - High-performance, massive-scale Vecto...</td>\n",
       "      <td>1,307</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Ripository Tiles  \\\n",
       "0       Stirling-Tools / Stirling-PDF   \n",
       "1                   Netflix / maestro   \n",
       "2           public-apis / public-apis   \n",
       "3              meta-llama / codellama   \n",
       "4                       mem0ai / mem0   \n",
       "5                  drawdb-io / drawdb   \n",
       "6   DarkFlippers / unleashed-firmware   \n",
       "7                  stretchr / testify   \n",
       "8                 meta-llama / llama3   \n",
       "9             hoppscotch / hoppscotch   \n",
       "10                    gabime / spdlog   \n",
       "11              ggerganov / llama.cpp   \n",
       "12                          lz4 / lz4   \n",
       "13          openstatusHQ / openstatus   \n",
       "14                    qdrant / qdrant   \n",
       "\n",
       "                               Ripository Description Contributors count  \\\n",
       "0   #1 Locally hosted web application that allows ...              2,537   \n",
       "1            Maestro: Netflix‚Äôs Workflow Orchestrator                 66   \n",
       "2                      A collective list of free APIs             32,809   \n",
       "3                 Inference code for CodeLlama models              1,819   \n",
       "4                The memory layer for Personalized AI              1,634   \n",
       "5   Free, simple, and intuitive online database de...                920   \n",
       "6                     Flipper Zero Unleashed Firmware              1,355   \n",
       "7   A toolkit with common assertions and mocks tha...              1,574   \n",
       "8               The official Meta Llama 3 GitHub site              2,594   \n",
       "9   Open source API development ecosystem - https:...              4,295   \n",
       "10                          Fast C++ logging library.              4,395   \n",
       "11                             LLM inference in C/C++              8,939   \n",
       "12               Extremely Fast Compression algorithm              1,354   \n",
       "13  üèì The open-source synthetic monitoring platform üèì                345   \n",
       "14  Qdrant - High-performance, massive-scale Vecto...              1,307   \n",
       "\n",
       "   Language Used  \n",
       "0           Java  \n",
       "1           Java  \n",
       "2         Python  \n",
       "3         Python  \n",
       "4         Python  \n",
       "5     JavaScript  \n",
       "6              C  \n",
       "7             Go  \n",
       "8         Python  \n",
       "9     TypeScript  \n",
       "10           C++  \n",
       "11           C++  \n",
       "12             C  \n",
       "13    TypeScript  \n",
       "14          Rust  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#click on Trending repository\n",
    "try:\n",
    "    trending = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[4]/div/div[3]/ul/li[2]/a')  \n",
    "    trending.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"Exception Raised\",e)\n",
    "    \n",
    "    \n",
    "#scraping the Repositor_Name \n",
    "r_nam=driver.find_elements(By.XPATH, '//h2[@class=\"h3 lh-condensed\"]')\n",
    "for i in r_nam:\n",
    "    if i.text is None :\n",
    "        R_title.append(\"--\") \n",
    "    else:\n",
    "        R_title.append(i.text)\n",
    "\n",
    "#scraping the Description \n",
    "r_des=driver.find_elements(By.XPATH, '//article[@class=\"Box-row\"]/p')\n",
    "for i in r_des:\n",
    "    if i.text is None :\n",
    "        R_discr.append(\"--\") \n",
    "    else:\n",
    "        R_discr.append(i.text)\n",
    "\n",
    "\n",
    "#scraping the Contribution Count\n",
    "contr=driver.find_elements(By.XPATH, \"//a[@class='Link Link--muted d-inline-block mr-3'][2]\")\n",
    "for i in contr:\n",
    "    if i.text is None :\n",
    "        contributers.append(\"--\") \n",
    "    else:\n",
    "        contributers.append(i.text)\n",
    "        \n",
    "    \n",
    "#scraping the Language\n",
    "lang=driver.find_elements(By.XPATH, \"//span[@itemprop='programmingLanguage']\")\n",
    "for i in lang:\n",
    "    if i.text is None :\n",
    "        Language.append(\"--\") \n",
    "    else:\n",
    "        Language.append(i.text)\n",
    "        \n",
    "        \n",
    "# check length of all scraping data\n",
    "print(\"Ripository Titles:\",len(R_title))\n",
    "print(\"Ripository Description:\",len(R_discr))\n",
    "print(\"Contributors Count:\",len(contributers))\n",
    "print(\"Language Ussed:\",len(Language))\n",
    "\n",
    "\n",
    "\n",
    "# making Data Frme\n",
    "trending_ripository_df=pd.DataFrame({\n",
    "    \"Ripository Tiles\":R_title,\n",
    "    \"Ripository Description\":R_discr,\n",
    "    \"Contributors count\":contributers,\n",
    "    \"Language Used\":Language\n",
    "})\n",
    "trending_ripository_df\n",
    "\n",
    "#close driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4096b26",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9703c4a8",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9076e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException ,ElementNotInteractableException,ElementClickInterceptedException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# get the web page\n",
    "driver = webdriver.Chrome()\n",
    "url=\"https://www.billboard.com/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "# from home page click on chart option by code\n",
    "try:\n",
    "    time.sleep(2)\n",
    "    explore_chart=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a\")\n",
    "    explore_chart.click()\n",
    "except NoSuchElementException:\n",
    "    driver.get(explore_chart.get_attribute('href'))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b86d9b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on hot 100 option by codes\n",
    "try:\n",
    "    time.sleep(2)\n",
    "    hot_100=driver.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[3]/div/div/div[2]/div/div[1]/a/span\")\n",
    "    hot_100.click()\n",
    "except NoSuchElementException:\n",
    "    driver.get(hot_100.get_attribute('href'))\n",
    "except ElementClickInterceptedException as e:\n",
    "    print(\"Raised Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ccc61973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 100\n",
      "Artist 100\n",
      "Week Rank 100\n",
      "Peak rank 100\n",
      "week on Boards 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks_on_chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Bar Song (Tipsy)</td>\n",
       "      <td>Shaboozey</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I Had Some Help</td>\n",
       "      <td>Post Malone Featuring Morgan Wallen</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Like Us</td>\n",
       "      <td>Kendrick Lamar</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Million Dollar Baby</td>\n",
       "      <td>Tommy Richman</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Espresso</td>\n",
       "      <td>Sabrina Carpenter</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Bass Boat</td>\n",
       "      <td>Zach Bryan</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Think I'm In Love With You</td>\n",
       "      <td>Chris Stapleton</td>\n",
       "      <td>87</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Beautiful As You</td>\n",
       "      <td>Thomas Rhett</td>\n",
       "      <td>95</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Sweet Dreams</td>\n",
       "      <td>Koe Wetzel</td>\n",
       "      <td>88</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Sandpaper</td>\n",
       "      <td>Zach Bryan Featuring Bruce Springsteen</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Song_Name                             Artist_Name  \\\n",
       "0           A Bar Song (Tipsy)                               Shaboozey   \n",
       "1              I Had Some Help     Post Malone Featuring Morgan Wallen   \n",
       "2                  Not Like Us                          Kendrick Lamar   \n",
       "3          Million Dollar Baby                           Tommy Richman   \n",
       "4                     Espresso                       Sabrina Carpenter   \n",
       "..                         ...                                     ...   \n",
       "95                   Bass Boat                              Zach Bryan   \n",
       "96  Think I'm In Love With You                         Chris Stapleton   \n",
       "97            Beautiful As You                            Thomas Rhett   \n",
       "98                Sweet Dreams                              Koe Wetzel   \n",
       "99                   Sandpaper  Zach Bryan Featuring Bruce Springsteen   \n",
       "\n",
       "   Last_week_rank Peak Rank Weeks_on_chart  \n",
       "0               2         1             14  \n",
       "1               3         1             10  \n",
       "2               1         1             11  \n",
       "3               4         2             12  \n",
       "4               5         3             14  \n",
       "..            ...       ...            ...  \n",
       "95             61        61              2  \n",
       "96             87        49             11  \n",
       "97             95        83              6  \n",
       "98             88        35              9  \n",
       "99             71        71              2  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the list for store scraoing data\n",
    "Song_name=[]\n",
    "Artist_name = []\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]\n",
    "\n",
    "    \n",
    "# scraping Song name\n",
    "try:\n",
    "    time.sleep(5)\n",
    "    for i in driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/h3'):\n",
    "        Song_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Song_name.append('-')\n",
    "\n",
    "# scraping Artist name\n",
    "try:\n",
    "    time.sleep(5)\n",
    "    for i in driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/span'):\n",
    "        Artist_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist_name.append('-')\n",
    "Artist_name=Artist_name[0:-1:4]\n",
    "\n",
    "\n",
    "#scraping the Last_Week Rank\n",
    "try:\n",
    "    time.sleep(3)\n",
    "    for i in driver.find_elements(By.XPATH, '//div[@class=\"chart-results-list // lrv-u-padding-t-150 lrv-u-padding-t-050@mobile-max\"]/div/ul/li/ul/li[4]/span'):\n",
    "        Last_week_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Last_week_rank.append('-')\n",
    "    \n",
    "\n",
    "#scraping the peak rank\n",
    "try:\n",
    "    time.sleep(3)\n",
    "    for i in driver.find_elements(By.XPATH, '//div[@class=\"chart-results-list // lrv-u-padding-t-150 lrv-u-padding-t-050@mobile-max\"]/div/ul/li/ul/li[5]/span'):\n",
    "        Peak_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Peak_rank.append('-')\n",
    "    \n",
    "\n",
    "#scraping the week on board\n",
    "try:\n",
    "    time.sleep(3)\n",
    "    for i in driver.find_elements(By.XPATH, '//div[@class=\"chart-results-list // lrv-u-padding-t-150 lrv-u-padding-t-050@mobile-max\"]/div/ul/li/ul/li[6]/span'):\n",
    "        Weeks_on_board.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Weeks_on_board.append('-') \n",
    "\n",
    "#close wepage\n",
    "driver.quit()\n",
    "    \n",
    "# check the len of all scrapping data\n",
    "print(\"Song\",len(Song_name))\n",
    "print(\"Artist\",len(Artist_name))\n",
    "print(\"Week Rank\",len(Last_week_rank))\n",
    "print(\"Peak rank\",len(Peak_rank))\n",
    "print(\"week on Boards\",len(Weeks_on_board))\n",
    "\n",
    "\n",
    "# making The data frame\n",
    "Hot_100_song_df=pd.DataFrame({'Song_Name':Song_name,\n",
    "                'Artist_Name':Artist_name,\n",
    "                'Last_week_rank':Last_week_rank,\n",
    "                'Peak Rank':Peak_rank,\n",
    "                'Weeks_on_chart':Weeks_on_board})\n",
    "Hot_100_song_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24f8ae",
   "metadata": {},
   "source": [
    "# Question 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b9681",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb8a616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Name 100\n",
      "Author Name 100\n",
      "Volume Sold 100\n",
      "Publisher 100\n",
      "Genre 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException ,ElementNotInteractableException,ElementClickInterceptedException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# run webpage\n",
    "driver = webdriver.Chrome()\n",
    "url=\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "# create the list\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "#scraping Book_name \n",
    "try:\n",
    "    time.sleep(3)\n",
    "    b_nam=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[2]\")\n",
    "    for i in b_nam:\n",
    "        Book_name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Book_name.append(\"Not Present\")\n",
    "\n",
    "#scraping Author_name\n",
    "try:\n",
    "    time.sleep(3)\n",
    "    Auth=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]\")\n",
    "    for i in Auth:\n",
    "        Author_name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Author_name.append(\"Not Present\")\n",
    "    \n",
    "#scraping Volumes_sold \n",
    "try:\n",
    "    time.sleep(3)\n",
    "    volum=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[4]\")\n",
    "    for i in volum:\n",
    "        Volumes_sold.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Volumes_sold.append(\"Not Present\")\n",
    "    \n",
    "#scraping Publisher\n",
    "try:\n",
    "    time.sleep(3)\n",
    "    publice=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[5]\")\n",
    "    for i in publice:\n",
    "        Publisher.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Publisher.append(\"Not Present\")\n",
    "    \n",
    "#scraping the Genre \n",
    "try:\n",
    "    time.sleep(3)\n",
    "    gen=driver.find_elements(By.XPATH, \"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[6]\")\n",
    "    for i in gen:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Genre.append(\"Not Present\")\n",
    "    \n",
    "#close web page\n",
    "driver.quit()\n",
    "\n",
    "#check length of all scrapping data\n",
    "print(\"Book Name\",len(Book_name))\n",
    "print(\"Author Name\",len(Author_name))\n",
    "print(\"Volume Sold\",len(Volumes_sold))\n",
    "print(\"Publisher\",len(Publisher))\n",
    "print(\"Genre\",len(Genre))\n",
    "\n",
    "\n",
    "#Create data Frame\n",
    "Novel_df=pd.DataFrame({\n",
    "    \"Book Name\":Book_name,\n",
    "    \"Author Name\":Author_name,\n",
    "    \"Volume Sold\":Volumes_sold,\n",
    "    \"Publisher\":Publisher,\n",
    "    \"Genre\":Genre})\n",
    "\n",
    "Novel_df\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bef06d",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369f8ed0",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have\n",
    "to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e9adb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException ,ElementNotInteractableException,ElementClickInterceptedException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# get web page\n",
    "driver = webdriver.Chrome()\n",
    "url=\"https://www.imdb.com/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "# click on menu\n",
    "try:\n",
    "    menu= driver.find_element(By.XPATH, '//div[@class=\"ipc-page-content-container ipc-page-content-container--center navbar__inner\"]/label[1]')      \n",
    "    menu.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33b37e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on Most Popular Tv Shows\n",
    "try:\n",
    "    tv_shows= driver.find_element(By.XPATH, '/html/body/div[2]/nav/div[2]/aside[1]/div/div[2]/div/div[2]/div[1]/span/div/div/ul/a[3]/span')      \n",
    "    tv_shows.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc5eda3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of Movies 108\n",
      "Year of Span 100\n",
      "Ratings Of Movies 99\n",
      "Votes 99\n",
      "Genres 96\n",
      "Run Time 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Movies</th>\n",
       "      <th>Year of Span</th>\n",
       "      <th>Ratings Of Movies</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Boys</td>\n",
       "      <td>2019‚Äì</td>\n",
       "      <td>8.7</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>40 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House of the Dragon</td>\n",
       "      <td>2022‚Äì</td>\n",
       "      <td>8.4</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>20 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Bear</td>\n",
       "      <td>2022‚Äì</td>\n",
       "      <td>8.6</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>29 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Acolyte</td>\n",
       "      <td>2024‚Äì</td>\n",
       "      <td>3.9</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>8 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Presumed Innocent</td>\n",
       "      <td>2024</td>\n",
       "      <td>7.8</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>9 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>The White Lotus</td>\n",
       "      <td>2021‚Äì2025</td>\n",
       "      <td>8.6</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>14 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>The X-Files</td>\n",
       "      <td>1993‚Äì2018</td>\n",
       "      <td>7.2</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>217 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Under the Bridge</td>\n",
       "      <td>2024</td>\n",
       "      <td>8.6</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>8 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Sons of Anarchy</td>\n",
       "      <td>2008‚Äì2014</td>\n",
       "      <td>7.9</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>92 eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The Umbrella Academy</td>\n",
       "      <td>2019‚Äì2024</td>\n",
       "      <td>8.0</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>36 eps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name of Movies Year of Span Ratings Of Movies Genres Run Time\n",
       "0               The Boys        2019‚Äì               8.7  TV-MA   40 eps\n",
       "1    House of the Dragon        2022‚Äì               8.4  TV-MA   20 eps\n",
       "2               The Bear        2022‚Äì               8.6  TV-MA   29 eps\n",
       "3            The Acolyte        2024‚Äì               3.9  TV-14    8 eps\n",
       "4      Presumed Innocent         2024               7.8  TV-MA    9 eps\n",
       "..                   ...          ...               ...    ...      ...\n",
       "91       The White Lotus    2021‚Äì2025               8.6  TV-14   14 eps\n",
       "92           The X-Files    1993‚Äì2018               7.2  TV-14  217 eps\n",
       "93      Under the Bridge         2024               8.6  TV-14    8 eps\n",
       "94       Sons of Anarchy    2008‚Äì2014               7.9  TV-14   92 eps\n",
       "95  The Umbrella Academy    2019‚Äì2024               8.0  TV-MA   36 eps\n",
       "\n",
       "[96 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maiking lists for store the scraping data\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genres=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "\n",
    "#scraping the Name\n",
    "try:\n",
    "    nam=driver.find_elements(By.XPATH, '//a[@class=\"ipc-title-link-wrapper\"]')\n",
    "    for i in nam:\n",
    "        if i.text is None :\n",
    "            Name.append(\"--\")\n",
    "        else:\n",
    "            Name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)\n",
    "    \n",
    "#scraping the Year_span     \n",
    "try:\n",
    "    year=driver.find_elements(By.XPATH, '//div[@class=\"sc-b189961a-7 btCcOY cli-title-metadata\"]/span[1]')\n",
    "    for i in year:\n",
    "        if i.text is None :\n",
    "            Year_span.append(\"--\")     \n",
    "        else:\n",
    "            Year_span.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)\n",
    "    \n",
    "    \n",
    "#scraping the Ratings\n",
    "try:\n",
    "    rate=driver.find_elements(By.XPATH, '//span[@class=\"ipc-rating-star--rating\"]')\n",
    "    for i in rate:\n",
    "        if i.text is None :           \n",
    "            Ratings.append(\"--\")      \n",
    "        else:\n",
    "            Ratings.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)\n",
    "    \n",
    "    \n",
    "    \n",
    "#scraping the Votes \n",
    "try:\n",
    "    vot=driver.find_elements(By.XPATH, '//span[@class=\"ipc-rating-star--voteCount\"]')\n",
    "    for i in vot:\n",
    "        if i.text is None :\n",
    "            Votes.append(\"--\") \n",
    "        else:\n",
    "            Votes.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Scraping the Genre\n",
    "try:\n",
    "    genr=driver.find_elements(By.XPATH, '//div[@class=\"sc-b189961a-7 btCcOY cli-title-metadata\"]/span[3]')\n",
    "    for i in genr:\n",
    "        if i.text is None :\n",
    "            Genres.append(\"--\") \n",
    "        else:\n",
    "            Genres.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)\n",
    "    \n",
    "\n",
    "\n",
    "# Scraping the RunTime\n",
    "try:\n",
    "    runtime=driver.find_elements(By.XPATH, '//div[@class=\"sc-b189961a-7 btCcOY cli-title-metadata\"]/span[2]')\n",
    "    for i in runtime:\n",
    "        if i.text is None :\n",
    "            Run_time.append(\"--\") \n",
    "        else:\n",
    "            Run_time.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)\n",
    "    \n",
    "# close driver\n",
    "driver.quit()\n",
    "    \n",
    "# print the length of all scrapping data\n",
    "print(\"Name of Movies\",len(Name))\n",
    "print(\"Year of Span\",len(Year_span))\n",
    "print(\"Ratings Of Movies\",len(Ratings))\n",
    "print(\"Votes\",len(Votes))\n",
    "print(\"Genres\",len(Genres))\n",
    "print(\"Run Time\",len(Run_time))\n",
    "\n",
    "# make Data frame of Popular Tv shows\n",
    "Popular_Tv_shows_df=pd.DataFrame({\n",
    "    \"Name of Movies\":Name[:96],\n",
    "    \"Year of Span\":Year_span[:96],\n",
    "    \"Ratings Of Movies\":Ratings[:96],\n",
    "    \"Genres\":Genres[:96],\n",
    "    \"Run Time\":Run_time[:96]\n",
    "})\n",
    "\n",
    "Popular_Tv_shows_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119bb3bd",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea905e",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You\n",
    "have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    " Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44b3e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import regex as re\n",
    "#exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException ,TimeoutException,StaleElementReferenceException ,ElementNotInteractableException,ElementClickInterceptedException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# get the web page \n",
    "driver=webdriver.Chrome()\n",
    "url=\"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "# show all data set throgh codes\n",
    "try :\n",
    "    time.sleep(3)\n",
    "    all_dataset= driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')      \n",
    "    all_dataset.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"raised Exception\",e)\n",
    "    \n",
    "#create the Lists for storing Data\n",
    "Dataset_Name=[]\n",
    "Data_Type=[]\n",
    "Task=[]\n",
    "No_of_Instances=[]\n",
    "No_of_Attribute=[]\n",
    "Attribute_type=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "159e248b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets Name 10\n",
      "Dataset Type 10\n",
      "Task 10\n",
      "Num. of Instances 10\n",
      "Num. of attributes 10\n",
      "URL Datasets 10\n",
      "Attribute Type 10\n",
      "years 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datasets Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>No_of_Instances</th>\n",
       "      <th>No_of_Attribute</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>Real</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>Donated on 9/13/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>Real</td>\n",
       "      <td>Donated on 10/5/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>900 Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>Real, Integer</td>\n",
       "      <td>Donated on 8/13/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>Donated on 4/30/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>Real</td>\n",
       "      <td>Donated on 10/31/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>Donated on 6/30/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>Real</td>\n",
       "      <td>Donated on 10/6/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bank Marketing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>45.21K Instances</td>\n",
       "      <td>17 Features</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>Donated on 2/13/2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Datasets Name     Data Type  \\\n",
       "0                                  Iris       Tabular   \n",
       "1                              Dry Bean  Multivariate   \n",
       "2                         Heart Disease  Multivariate   \n",
       "3            Rice (Cammeo and Osmancik)  Multivariate   \n",
       "4                                Raisin  Multivariate   \n",
       "5                                 Adult  Multivariate   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)  Multivariate   \n",
       "7                                  Wine       Tabular   \n",
       "8                          Wine Quality  Multivariate   \n",
       "9                        Bank Marketing  Multivariate   \n",
       "\n",
       "                         Task   No_of_Instances No_of_Attribute  \\\n",
       "0              Classification     150 Instances      4 Features   \n",
       "1              Classification  13.61K Instances     16 Features   \n",
       "2              Classification     303 Instances     13 Features   \n",
       "3              Classification   3.81K Instances      7 Features   \n",
       "4              Classification     900 Instances      8 Features   \n",
       "5              Classification  48.84K Instances     14 Features   \n",
       "6              Classification     569 Instances     30 Features   \n",
       "7              Classification     178 Instances     13 Features   \n",
       "8  Classification, Regression    4.9K Instances     12 Features   \n",
       "9              Classification  45.21K Instances     17 Features   \n",
       "\n",
       "               Attribute_type                   Year  \n",
       "0                        Real   Donated on 6/30/1988  \n",
       "1               Integer, Real   Donated on 9/13/2020  \n",
       "2  Categorical, Integer, Real   Donated on 6/30/1988  \n",
       "3                        Real   Donated on 10/5/2019  \n",
       "4               Real, Integer   Donated on 8/13/2023  \n",
       "5        Categorical, Integer   Donated on 4/30/1996  \n",
       "6                        Real  Donated on 10/31/1995  \n",
       "7               Integer, Real   Donated on 6/30/1991  \n",
       "8                        Real   Donated on 10/6/2009  \n",
       "9        Categorical, Integer   Donated on 2/13/2012  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the Dataset_Name\n",
    "\n",
    "data_nam=driver.find_elements(By.XPATH, '//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in data_nam:\n",
    "    if i.text is None :\n",
    "        Dataset_Name.append(\"--\") \n",
    "    else:\n",
    "        Dataset_Name.append(i.text)\n",
    "        \n",
    "#scraping the Data_Type \n",
    "\n",
    "data_typ=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]')\n",
    "for i in data_typ:\n",
    "    if i.text is None :\n",
    "        Data_Type.append(\"--\") \n",
    "    else:\n",
    "        Data_Type.append(i.text)\n",
    "\n",
    "#scraping the Task\n",
    "\n",
    "tsk=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]')\n",
    "for i in tsk:\n",
    "    if i.text is None :\n",
    "        Task.append(\"--\") \n",
    "    else:\n",
    "        Task.append(i.text)\n",
    "\n",
    "#scraping the No_of_Instances \n",
    "\n",
    "instance=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]')\n",
    "for i in instance:\n",
    "    if i.text is None :\n",
    "        No_of_Instances.append(\"--\") \n",
    "    else:\n",
    "        No_of_Instances.append(i.text)\n",
    "\n",
    "#scraping the No_of_Attribute\n",
    "\n",
    "num_atrribute=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]')\n",
    "for i in num_atrribute:\n",
    "    if i.text is None :\n",
    "        No_of_Attribute.append(\"--\") \n",
    "    else:\n",
    "        No_of_Attribute.append(i.text)\n",
    "        \n",
    "# check length of scrapping data\n",
    "print(\"Datasets Name\",len(Dataset_Name))\n",
    "print(\"Dataset Type\",len(Data_Type))\n",
    "print(\"Task\",len(Task))\n",
    "print(\"Num. of Instances\",len(No_of_Instances))\n",
    "print(\"Num. of attributes\",len(No_of_Attribute))\n",
    "\n",
    "\n",
    "\n",
    "# scrape the dataset URL\n",
    "urls_dataset=[]\n",
    "time.sleep(3)\n",
    "url_dataset=driver.find_elements(By.XPATH,'//div[@class=\"h-12 w-12 rounded\"]/a')\n",
    "for i in url_dataset:\n",
    "    urls_dataset.append(i.get_attribute('href'))\n",
    "\n",
    "\n",
    "\n",
    "# scrape the attribute type and year\n",
    "for i in urls_dataset:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        a_type=driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]//div[4]//p')\n",
    "        for a in a_type:\n",
    "            Attribute_type.append(a.text)\n",
    "            \n",
    "        years=driver.find_elements(By.XPATH,'//div[@class=\"relative flex flex w-full items-center gap-4 bg-primary p-2\"]/div[2]/h2')\n",
    "        for a in years:\n",
    "            Year.append(a.text)\n",
    "            \n",
    "    except NoSuchElementException as e:\n",
    "        Attribute_type.append('No Present')\n",
    "        \n",
    "# check length again\n",
    "print(\"URL Datasets\",len(urls_dataset))\n",
    "print(\"Attribute Type\",len(Attribute_type))\n",
    "print(\"years\",len(Year))\n",
    " \n",
    "# close web page\n",
    "driver.close()\n",
    "\n",
    "# make DataFrame\n",
    "All_datasets_df=pd.DataFrame({\n",
    "    \"Datasets Name\":Dataset_Name,\n",
    "    \"Data Type\":Data_Type,\n",
    "    \"Task\":Task,\n",
    "    \"No_of_Instances\":No_of_Instances,\n",
    "    \"No_of_Attribute\":No_of_Attribute,\n",
    "    \"Attribute_type\":Attribute_type,\n",
    "    \"Year\":Year\n",
    "})\n",
    "\n",
    "All_datasets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebababe",
   "metadata": {},
   "source": [
    "# Or We can Do 8rth Question like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12a2dcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception raised Message: element click intercepted: Element <button class=\"btn-primary btn-sm btn\" aria-label=\"Next Page\">...</button> is not clickable at point (1309, 573). Other element would receive the click: <div class=\"alert fixed bottom-0\">...</div>\n",
      "  (Session info: chrome=126.0.6478.183)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF636B0EEB2+31554]\n",
      "\t(No symbol) [0x00007FF636A87EE9]\n",
      "\t(No symbol) [0x00007FF63694872A]\n",
      "\t(No symbol) [0x00007FF6369A012E]\n",
      "\t(No symbol) [0x00007FF63699DAF2]\n",
      "\t(No symbol) [0x00007FF63699AF8B]\n",
      "\t(No symbol) [0x00007FF63699A156]\n",
      "\t(No symbol) [0x00007FF63698C151]\n",
      "\t(No symbol) [0x00007FF6369BD02A]\n",
      "\t(No symbol) [0x00007FF63698BA76]\n",
      "\t(No symbol) [0x00007FF6369BD240]\n",
      "\t(No symbol) [0x00007FF6369DC977]\n",
      "\t(No symbol) [0x00007FF6369BCDD3]\n",
      "\t(No symbol) [0x00007FF63698A33B]\n",
      "\t(No symbol) [0x00007FF63698AED1]\n",
      "\tGetHandleVerifier [0x00007FF636E18B2D+3217341]\n",
      "\tGetHandleVerifier [0x00007FF636E65AF3+3532675]\n",
      "\tGetHandleVerifier [0x00007FF636E5B0F0+3489152]\n",
      "\tGetHandleVerifier [0x00007FF636BBE786+750614]\n",
      "\t(No symbol) [0x00007FF636A9376F]\n",
      "\t(No symbol) [0x00007FF636A8EB24]\n",
      "\t(No symbol) [0x00007FF636A8ECB2]\n",
      "\t(No symbol) [0x00007FF636A7E17F]\n",
      "\tBaseThreadInitThunk [0x00007FF8FB3A7374+20]\n",
      "\tRtlUserThreadStart [0x00007FF8FBE5CC91+33]\n",
      "\n",
      "Datasets Name 650\n",
      "Dataset Type 650\n",
      "Task 650\n",
      "Num. of Instances 650\n",
      "Num. of attributes 650\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datasets Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>No_of_Instances</th>\n",
       "      <th>No_of_Attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>900 Instances</td>\n",
       "      <td>8 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>Bank Marketing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>45.21K Instances</td>\n",
       "      <td>17 Features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Datasets Name     Data Type  \\\n",
       "0                                    Iris       Tabular   \n",
       "1                                Dry Bean  Multivariate   \n",
       "2                           Heart Disease  Multivariate   \n",
       "3              Rice (Cammeo and Osmancik)  Multivariate   \n",
       "4                                  Raisin  Multivariate   \n",
       "..                                    ...           ...   \n",
       "645                                 Adult  Multivariate   \n",
       "646  Breast Cancer Wisconsin (Diagnostic)  Multivariate   \n",
       "647                                  Wine       Tabular   \n",
       "648                          Wine Quality  Multivariate   \n",
       "649                        Bank Marketing  Multivariate   \n",
       "\n",
       "                           Task   No_of_Instances No_of_Attribute  \n",
       "0                Classification     150 Instances      4 Features  \n",
       "1                Classification  13.61K Instances     16 Features  \n",
       "2                Classification     303 Instances     13 Features  \n",
       "3                Classification   3.81K Instances      7 Features  \n",
       "4                Classification     900 Instances      8 Features  \n",
       "..                          ...               ...             ...  \n",
       "645              Classification  48.84K Instances     14 Features  \n",
       "646              Classification     569 Instances     30 Features  \n",
       "647              Classification     178 Instances     13 Features  \n",
       "648  Classification, Regression    4.9K Instances     12 Features  \n",
       "649              Classification  45.21K Instances     17 Features  \n",
       "\n",
       "[650 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(5)\n",
    "start=0\n",
    "end=65\n",
    "for page in range(start,end):\n",
    "    data_nam=driver.find_elements(By.XPATH, '//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "    for i in data_nam:\n",
    "        Dataset_Name.append(i.text)\n",
    "        \n",
    "    data_typ=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]')\n",
    "    for i in data_typ:\n",
    "        Data_Type.append(i.text)\n",
    "        \n",
    "        \n",
    "    tsk=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]')\n",
    "    for i in tsk:\n",
    "        Task.append(i.text)\n",
    "         \n",
    "    \n",
    "    instance=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]')\n",
    "    for i in instance:\n",
    "        No_of_Instances.append(i.text)\n",
    "        \n",
    "    num_atrribute=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]')\n",
    "    for i in num_atrribute:\n",
    "        No_of_Attribute.append(i.text)\n",
    "\n",
    "try:\n",
    "    time.sleep(2)\n",
    "    next_button=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/div/button[2]')\n",
    "    for button in next_button:\n",
    "        button.click()\n",
    "except ElementClickInterceptedException as e:\n",
    "        print(\"exception raised\",e) \n",
    "        \n",
    "# check length of scrapping data\n",
    "print(\"Datasets Name\",len(Dataset_Name))\n",
    "print(\"Dataset Type\",len(Data_Type))\n",
    "print(\"Task\",len(Task))\n",
    "print(\"Num. of Instances\",len(No_of_Instances))\n",
    "print(\"Num. of attributes\",len(No_of_Attribute))\n",
    "\n",
    "\n",
    "# make DataFrame\n",
    "All_datasets_df=pd.DataFrame({\n",
    "    \"Datasets Name\":Dataset_Name,\n",
    "    \"Data Type\":Data_Type,\n",
    "    \"Task\":Task,\n",
    "    \"No_of_Instances\":No_of_Instances,\n",
    "    \"No_of_Attribute\":No_of_Attribute\n",
    "})\n",
    "\n",
    "All_datasets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f03acb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------THANK YOU----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------THANK YOU----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7580c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
